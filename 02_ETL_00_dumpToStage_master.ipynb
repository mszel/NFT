{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL 00: Reading and Pre-processing NFT data (raw --> stag)\n",
    "Reading the extended transaction file(s), and create the base files for the transaction, token and collection tables. After saving them to daily parquet files. </br>\n",
    "</br>\n",
    "There are 2 files which could be loaded as \"**ers**\":\n",
    " * ETL_00_rawToStage_new: the pandas version of the loaders\n",
    " * ETL_00_rawToStage_pyspark: the pyspark version of the loaders\n",
    "As the function names are the same, the notebook will work without any change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "_version = \"PANDAS\" # could be \"PYSPARK\" for GCP and \"PANDAS\" for local environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading ETL related libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# core libraries\n",
    "from datetime import datetime, timedelta\n",
    "import imp\n",
    "\n",
    "# OS related\n",
    "from os import listdir, makedirs, remove, path\n",
    "\n",
    "# parallel programming related\n",
    "from multiprocessing import Pool\n",
    "import subprocess\n",
    "\n",
    "# visualization related\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# settings\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# src loader functions, pathes, config values\n",
    "import src.config as cf\n",
    "\n",
    "if _version == \"PYSPARK\":\n",
    "    import src.ETL_00_rawToStage_pyspark as ers\n",
    "else:\n",
    "    import src.ETL_00_rawToStage_new as ers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ers = imp.reload(ers)\n",
    "cf = imp.reload(cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing: preprocessing one file\n",
    "With running this loader on a single file, the loader can be tested out, and the given tables can be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _testfilepath = cf.PATH_00RAW_API_dump_main + 'events_20170101_000000_20180101_000000/eventresponse_1498953600_1499558400.pickle'\n",
    "# ers._processOneFile(path_in_file_pkl=_testfilepath, path_out_trx_folder_pq='./data/01_stage/trx/', \n",
    "#                     path_out_token_folder_pq='./data/01_stage/token/', path_out_collection_folder_pq='./data/01_stage/collection/',\n",
    "#                     _verbose=False)\n",
    "\n",
    "# pdf_tokens = pd.read_parquet('./data/01_stage/token/')\n",
    "# pdf_collections = pd.read_parquet('./data/01_stage/collection/')\n",
    "# pdf_trxs = pd.read_parquet('./data/01_stage/trx/year=2021/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_tokens.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_collections.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_trxs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Preprocessing\n",
    "Running the preprocessing ETLs on the given list of folders (only checking the content of the folder, will not go to the subfolders). If a file is preprocessed and not the overwriting mode is used, the source file will be ignored. Be careful, the \"overwrite\" mode deletes all files in the given output folders!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ers = imp.reload(ers)\n",
    "\n",
    "ers.StageLoader(path_in_folder_list=['./data/00_dump/events_20170101_000000_20180101_000000/'], \n",
    "                path_out_trx_folder_pq='./data/01_stage/trx/', path_out_token_folder_pq='./data/01_stage/token/', \n",
    "                path_out_collection_folder_pq='./data/01_stage/collection/', path_io_meta_folder='./data/_meta/', \n",
    "                _mode='append', _njobs=4, _verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ers.StageLoader(path_in_folder_list=['./data/00_dump/events_20180101_000000_20190101_000000/', \n",
    "                                     './data/00_dump/events_20190101_000000_20200101_000000/', \n",
    "                                     './data/00_dump/events_20200101_000000_20210101_000000/', \n",
    "                                     './data/00_dump/events_20210101_000000_20210401_000000/', \n",
    "                                     './data/00_dump/events_20210401_000000_20210701_000000/'], \n",
    "                path_out_trx_folder_pq='./data/01_stage/trx/', path_out_token_folder_pq='./data/01_stage/token/', \n",
    "                path_out_collection_folder_pq='./data/01_stage/collection/', path_io_meta_folder='./data/_meta/', \n",
    "                _mode='append', _njobs=4, _verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the gotten tables\n",
    "With a few examples, checking the possible data issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a6613bf63225e9394175f1e2a262c6dd4ee2ff1bd210ad1657e6dcd2c752f3b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
